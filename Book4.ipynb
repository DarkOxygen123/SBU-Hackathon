{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imgXUY0ZBJzW",
        "outputId": "62c9f0a3-02e3-4c24-d2cb-ae3323b55161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import gc\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "-68FpfVlCp6M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "EDrwGATCEhfb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "from scipy.special import softmax"
      ],
      "metadata": {
        "id": "DQSGSa7zCqiu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "metadata": {
        "id": "Mg33znF9DVCf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install feature_engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKzmLP8jW9eM",
        "outputId": "0b783247-01cc-4d29-de00-f3a4acc77c6c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting feature_engine\n",
            "  Downloading feature_engine-1.6.2-py2.py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.9/328.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from feature_engine) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from feature_engine) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from feature_engine) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from feature_engine) (1.11.4)\n",
            "Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from feature_engine) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.3->feature_engine) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->feature_engine) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->feature_engine) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.4)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11.1->feature_engine) (23.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.4->statsmodels>=0.11.1->feature_engine) (1.16.0)\n",
            "Installing collected packages: feature_engine\n",
            "Successfully installed feature_engine-1.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from feature_engine.imputation import MeanMedianImputer\n",
        "from feature_engine.selection import DropConstantFeatures, SmartCorrelatedSelection, DropHighPSIFeatures\n",
        "\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "1IyVxMpxW0ZI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8USgYecSGJiD",
        "outputId": "777a6d40-5f2f-470d-e11e-ac3850370da2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m573.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.23.5)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Installing collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPvtr7DUCuwt",
        "outputId": "6eee292d-a7e5-42ba-dfa2-8a3aae6fb15f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow_addons.activations import sparsemax"
      ],
      "metadata": {
        "id": "7yojD6reCxTf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_x = pd.read_pickle(\"/content/drive/MyDrive/Competition/norm_final_x_train.pkl\")\n",
        "df_y = pd.read_pickle(\"/content/drive/MyDrive/Competition/final_y_train (1).pkl\")\n"
      ],
      "metadata": {
        "id": "F6T9lfFBBZnq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_test_df = pd.read_pickle(\"/content/drive/MyDrive/Competition/norm_final_test.pkl\")"
      ],
      "metadata": {
        "id": "hyBwy_L3e1oy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df_x.columns:\n",
        "    col_mean = df_x[col].mean()\n",
        "    df_x[col].fillna(col_mean, inplace=True)"
      ],
      "metadata": {
        "id": "Jbnv3UySbXrv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in final_test_df.columns:\n",
        "    col_mean = final_test_df[col].mean()\n",
        "    final_test_df[col].fillna(col_mean, inplace=True)"
      ],
      "metadata": {
        "id": "wA5Ec6eTceW4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "ZaEzu2TQcoWG",
        "outputId": "4be3e14e-79cf-4d79-875c-4aface0d65b7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        TransactionID  TransactionAmt  ProductCD     card1  card2     card3  \\\n",
              "0            0.000000        0.003109          4  0.540814  0.022  0.378788   \n",
              "1            0.000002        0.004769          4  0.188032  0.022  0.378788   \n",
              "2            0.000004        0.016645          4  0.199759  0.948  0.378788   \n",
              "3            0.000006        0.027744          4  0.574155  0.520  0.378788   \n",
              "4            0.000008        0.006612          4  0.978213  0.704  0.378788   \n",
              "...               ...             ...        ...       ...    ...       ...   \n",
              "506686       0.999992        0.009216          0  0.737583  0.550  0.643939   \n",
              "506687       0.999994        0.001183          0  0.123764  0.616  0.643939   \n",
              "506688       0.999996        0.004769          4  0.900207  0.780  0.378788   \n",
              "506689       0.999998        0.019663          4  0.897908  0.832  0.378788   \n",
              "506690       1.000000        0.002368          0  0.270867  0.136  0.333333   \n",
              "\n",
              "        card4     card5  card6     addr1  ...  id-35  id-36  id-37  id-38  \\\n",
              "0           3  0.919708      2  0.159091  ...      2      2      2      2   \n",
              "1           3  0.919708      2  0.452273  ...      2      2      2      2   \n",
              "2           3  0.919708      2  0.845455  ...      2      2      2      2   \n",
              "3           3  0.481752      2  0.238636  ...      2      2      2      2   \n",
              "4           2  0.124088      2  0.372727  ...      2      2      2      2   \n",
              "...       ...       ...    ...       ...  ...    ...    ...    ...    ...   \n",
              "506686      2  0.905109      2  0.418182  ...      2      2      2      2   \n",
              "506687      2  0.905109      2  0.436015  ...      0      0      1      0   \n",
              "506688      3  0.919708      2  0.515909  ...      2      2      2      2   \n",
              "506689      2  0.905109      2  0.175000  ...      2      2      2      2   \n",
              "506690      3  0.343066      1  0.436015  ...      0      0      1      0   \n",
              "\n",
              "        DeviceType  DeviceInfo  P_emaildomain_bin  P_emaildomain_suffix  \\\n",
              "0                2        2226           0.444444                   0.0   \n",
              "1                2        2226           0.000000                   0.0   \n",
              "2                2        2226           0.555556                   0.0   \n",
              "3                2        2226           0.444444                   0.0   \n",
              "4                2        2226           0.444444                   0.0   \n",
              "...            ...         ...                ...                   ...   \n",
              "506686           2        2226           0.444444                   0.0   \n",
              "506687           1         107           0.555556                   0.0   \n",
              "506688           2        2226           0.555556                   0.0   \n",
              "506689           2        2226           0.555556                   0.0   \n",
              "506690           1        1208           0.555556                   0.0   \n",
              "\n",
              "        R_emaildomain_bin  R_emaildomain_suffix  \n",
              "0                0.666667                  0.75  \n",
              "1                0.666667                  0.75  \n",
              "2                0.666667                  0.75  \n",
              "3                0.666667                  0.75  \n",
              "4                0.666667                  0.75  \n",
              "...                   ...                   ...  \n",
              "506686           0.444444                  0.00  \n",
              "506687           0.555556                  0.00  \n",
              "506688           0.666667                  0.75  \n",
              "506689           0.666667                  0.75  \n",
              "506690           0.555556                  0.00  \n",
              "\n",
              "[506691 rows x 436 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8d828f4-9a6f-4235-ab23-7c00cb4a7c2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>...</th>\n",
              "      <th>id-35</th>\n",
              "      <th>id-36</th>\n",
              "      <th>id-37</th>\n",
              "      <th>id-38</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>DeviceInfo</th>\n",
              "      <th>P_emaildomain_bin</th>\n",
              "      <th>P_emaildomain_suffix</th>\n",
              "      <th>R_emaildomain_bin</th>\n",
              "      <th>R_emaildomain_suffix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003109</td>\n",
              "      <td>4</td>\n",
              "      <td>0.540814</td>\n",
              "      <td>0.022</td>\n",
              "      <td>0.378788</td>\n",
              "      <td>3</td>\n",
              "      <td>0.919708</td>\n",
              "      <td>2</td>\n",
              "      <td>0.159091</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2226</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.004769</td>\n",
              "      <td>4</td>\n",
              "      <td>0.188032</td>\n",
              "      <td>0.022</td>\n",
              "      <td>0.378788</td>\n",
              "      <td>3</td>\n",
              "      <td>0.919708</td>\n",
              "      <td>2</td>\n",
              "      <td>0.452273</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2226</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.016645</td>\n",
              "      <td>4</td>\n",
              "      <td>0.199759</td>\n",
              "      <td>0.948</td>\n",
              "      <td>0.378788</td>\n",
              "      <td>3</td>\n",
              "      <td>0.919708</td>\n",
              "      <td>2</td>\n",
              "      <td>0.845455</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2226</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.027744</td>\n",
              "      <td>4</td>\n",
              "      <td>0.574155</td>\n",
              "      <td>0.520</td>\n",
              "      <td>0.378788</td>\n",
              "      <td>3</td>\n",
              "      <td>0.481752</td>\n",
              "      <td>2</td>\n",
              "      <td>0.238636</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2226</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.006612</td>\n",
              "      <td>4</td>\n",
              "      <td>0.978213</td>\n",
              "      <td>0.704</td>\n",
              "      <td>0.378788</td>\n",
              "      <td>2</td>\n",
              "      <td>0.124088</td>\n",
              "      <td>2</td>\n",
              "      <td>0.372727</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2226</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506686</th>\n",
              "      <td>0.999992</td>\n",
              "      <td>0.009216</td>\n",
              "      <td>0</td>\n",
              "      <td>0.737583</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.643939</td>\n",
              "      <td>2</td>\n",
              "      <td>0.905109</td>\n",
              "      <td>2</td>\n",
              "      <td>0.418182</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2226</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506687</th>\n",
              "      <td>0.999994</td>\n",
              "      <td>0.001183</td>\n",
              "      <td>0</td>\n",
              "      <td>0.123764</td>\n",
              "      <td>0.616</td>\n",
              "      <td>0.643939</td>\n",
              "      <td>2</td>\n",
              "      <td>0.905109</td>\n",
              "      <td>2</td>\n",
              "      <td>0.436015</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>107</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506688</th>\n",
              "      <td>0.999996</td>\n",
              "      <td>0.004769</td>\n",
              "      <td>4</td>\n",
              "      <td>0.900207</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.378788</td>\n",
              "      <td>3</td>\n",
              "      <td>0.919708</td>\n",
              "      <td>2</td>\n",
              "      <td>0.515909</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2226</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506689</th>\n",
              "      <td>0.999998</td>\n",
              "      <td>0.019663</td>\n",
              "      <td>4</td>\n",
              "      <td>0.897908</td>\n",
              "      <td>0.832</td>\n",
              "      <td>0.378788</td>\n",
              "      <td>2</td>\n",
              "      <td>0.905109</td>\n",
              "      <td>2</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2226</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506690</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.002368</td>\n",
              "      <td>0</td>\n",
              "      <td>0.270867</td>\n",
              "      <td>0.136</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.343066</td>\n",
              "      <td>1</td>\n",
              "      <td>0.436015</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1208</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>506691 rows × 436 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8d828f4-9a6f-4235-ab23-7c00cb4a7c2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c8d828f4-9a6f-4235-ab23-7c00cb4a7c2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c8d828f4-9a6f-4235-ab23-7c00cb4a7c2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c0a0e3a6-c29a-4e72-a0f5-1f5073d0741d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0a0e3a6-c29a-4e72-a0f5-1f5073d0741d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c0a0e3a6-c29a-4e72-a0f5-1f5073d0741d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_548e5fb4-3dd1-47f7-80e8-4e874aecda73\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('final_test_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_548e5fb4-3dd1-47f7-80e8-4e874aecda73 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('final_test_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = 0\n",
        "for i in final_test_df.isnull().sum():\n",
        "    print(i)\n",
        "    k+=1\n",
        "\n",
        "print(k)\n",
        ""
      ],
      "metadata": {
        "id": "iFql7i82a2sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "hoA2OEljarig",
        "outputId": "5a9e0ce5-1b2b-4f96-8bae-df7a8143191b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        TransactionID  TransactionAmt  ProductCD     card1  card2     card3  \\\n",
              "0            0.000000        0.002137          4  0.743044    NaN  0.381679   \n",
              "1            0.000002        0.000900          4  0.100885  0.608  0.381679   \n",
              "2            0.000003        0.001840          4  0.210566  0.780  0.381679   \n",
              "3            0.000005        0.001558          4  0.984824  0.934  0.381679   \n",
              "4            0.000007        0.001558          1  0.201023  0.828  0.381679   \n",
              "...               ...             ...        ...       ...    ...       ...   \n",
              "590535       0.999993        0.001526          4  0.319039    NaN  0.381679   \n",
              "590536       0.999995        0.001229          4  0.542883  0.250  0.381679   \n",
              "590537       0.999997        0.000961          4  0.634456  0.990  0.381679   \n",
              "590538       0.999998        0.003656          4  0.392389  0.762  0.381679   \n",
              "590539       1.000000        0.008760          4  0.808577  0.140  0.381679   \n",
              "\n",
              "        card4     card5  card6     addr1  ...  id_35  id_36  id_37  id_38  \\\n",
              "0           2  0.306569      2  0.488636  ...      2      2      2      2   \n",
              "1           3  0.014599      2  0.511364  ...      2      2      2      2   \n",
              "2           4  0.481752      3  0.522727  ...      2      2      2      2   \n",
              "3           3  0.124088      3  0.854545  ...      2      2      2      2   \n",
              "4           3  0.014599      2  0.727273  ...      1      0      1      1   \n",
              "...       ...       ...    ...       ...  ...    ...    ...    ...    ...   \n",
              "590535      4  0.919708      3  0.390909  ...      2      2      2      2   \n",
              "590536      3  0.905109      3  0.236364  ...      2      2      2      2   \n",
              "590537      3  0.905109      3  0.297727  ...      2      2      2      2   \n",
              "590538      3  0.905109      3  0.652273  ...      2      2      2      2   \n",
              "590539      3  0.014599      2  0.452273  ...      2      2      2      2   \n",
              "\n",
              "        DeviceType  DeviceInfo  P_emaildomain_bin  P_emaildomain_suffix  \\\n",
              "0                2        1786           0.666667                  0.75   \n",
              "1                2        1786           0.444444                  0.00   \n",
              "2                2        1786           0.555556                  0.00   \n",
              "3                2        1786           1.000000                  0.00   \n",
              "4                1         954           0.444444                  0.00   \n",
              "...            ...         ...                ...                   ...   \n",
              "590535           2        1786           0.666667                  0.75   \n",
              "590536           2        1786           0.444444                  0.00   \n",
              "590537           2        1786           0.444444                  0.00   \n",
              "590538           2        1786           0.000000                  0.00   \n",
              "590539           2        1786           0.444444                  0.00   \n",
              "\n",
              "        R_emaildomain_bin  R_emaildomain_suffix  \n",
              "0                0.666667                  0.75  \n",
              "1                0.666667                  0.75  \n",
              "2                0.666667                  0.75  \n",
              "3                0.666667                  0.75  \n",
              "4                0.666667                  0.75  \n",
              "...                   ...                   ...  \n",
              "590535           0.666667                  0.75  \n",
              "590536           0.666667                  0.75  \n",
              "590537           0.666667                  0.75  \n",
              "590538           0.666667                  0.75  \n",
              "590539           0.666667                  0.75  \n",
              "\n",
              "[590540 rows x 436 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ea86e4e-0e76-49c4-9be5-46c4aa74f338\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>...</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>DeviceInfo</th>\n",
              "      <th>P_emaildomain_bin</th>\n",
              "      <th>P_emaildomain_suffix</th>\n",
              "      <th>R_emaildomain_bin</th>\n",
              "      <th>R_emaildomain_suffix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002137</td>\n",
              "      <td>4</td>\n",
              "      <td>0.743044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>2</td>\n",
              "      <td>0.306569</td>\n",
              "      <td>2</td>\n",
              "      <td>0.488636</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1786</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>4</td>\n",
              "      <td>0.100885</td>\n",
              "      <td>0.608</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>3</td>\n",
              "      <td>0.014599</td>\n",
              "      <td>2</td>\n",
              "      <td>0.511364</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1786</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001840</td>\n",
              "      <td>4</td>\n",
              "      <td>0.210566</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>4</td>\n",
              "      <td>0.481752</td>\n",
              "      <td>3</td>\n",
              "      <td>0.522727</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1786</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.001558</td>\n",
              "      <td>4</td>\n",
              "      <td>0.984824</td>\n",
              "      <td>0.934</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>3</td>\n",
              "      <td>0.124088</td>\n",
              "      <td>3</td>\n",
              "      <td>0.854545</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1786</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.001558</td>\n",
              "      <td>1</td>\n",
              "      <td>0.201023</td>\n",
              "      <td>0.828</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>3</td>\n",
              "      <td>0.014599</td>\n",
              "      <td>2</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>954</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590535</th>\n",
              "      <td>0.999993</td>\n",
              "      <td>0.001526</td>\n",
              "      <td>4</td>\n",
              "      <td>0.319039</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>4</td>\n",
              "      <td>0.919708</td>\n",
              "      <td>3</td>\n",
              "      <td>0.390909</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1786</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590536</th>\n",
              "      <td>0.999995</td>\n",
              "      <td>0.001229</td>\n",
              "      <td>4</td>\n",
              "      <td>0.542883</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>3</td>\n",
              "      <td>0.905109</td>\n",
              "      <td>3</td>\n",
              "      <td>0.236364</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1786</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590537</th>\n",
              "      <td>0.999997</td>\n",
              "      <td>0.000961</td>\n",
              "      <td>4</td>\n",
              "      <td>0.634456</td>\n",
              "      <td>0.990</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>3</td>\n",
              "      <td>0.905109</td>\n",
              "      <td>3</td>\n",
              "      <td>0.297727</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1786</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590538</th>\n",
              "      <td>0.999998</td>\n",
              "      <td>0.003656</td>\n",
              "      <td>4</td>\n",
              "      <td>0.392389</td>\n",
              "      <td>0.762</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>3</td>\n",
              "      <td>0.905109</td>\n",
              "      <td>3</td>\n",
              "      <td>0.652273</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1786</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590539</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008760</td>\n",
              "      <td>4</td>\n",
              "      <td>0.808577</td>\n",
              "      <td>0.140</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>3</td>\n",
              "      <td>0.014599</td>\n",
              "      <td>2</td>\n",
              "      <td>0.452273</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1786</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>590540 rows × 436 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ea86e4e-0e76-49c4-9be5-46c4aa74f338')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ea86e4e-0e76-49c4-9be5-46c4aa74f338 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ea86e4e-0e76-49c4-9be5-46c4aa74f338');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ca0208fa-efc4-4572-af74-a1a5585e3250\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca0208fa-efc4-4572-af74-a1a5585e3250')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ca0208fa-efc4-4572-af74-a1a5585e3250 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_22d4bda4-9e39-4597-9eb5-354a16c9c758\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_x')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_22d4bda4-9e39-4597-9eb5-354a16c9c758 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_x');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.to_pickle('/content/drive/MyDrive/Competition/X_train')\n",
        "X_val.to_pickle('/content/drive/MyDrive/Competition/X_val')\n",
        "y_train.to_pickle('/content/drive/MyDrive/Competition/y_train')\n",
        "y_val.to_pickle('/content/drive/MyDrive/Competition/y_val')"
      ],
      "metadata": {
        "id": "Kl6_zXF-ddKK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_test_df.to_pickle('/content/drive/MyDrive/Competition/main_test')"
      ],
      "metadata": {
        "id": "-s4Wud1Aep4k"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(df_x, df_y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "BfhD-xp3C2oO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del final_test_df"
      ],
      "metadata": {
        "id": "HX8c9UM2e539"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myRQp93Pe9f-",
        "outputId": "05c43ff5-a72c-4354-e110-33c14920e72d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvTU1wYCdWn5",
        "outputId": "27c2e3ab-ef25-4b56-e8d8-907389bcc1e5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "A-UBm1XLJuPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ebf0de4-bb66-45bf-969f-76030c11ef5c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(472432, 436)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.read_pickle('/content/drive/MyDrive/Competition/X_train')\n",
        "X_val = pd.read_pickle('/content/drive/MyDrive/Competition/X_val')\n",
        "y_train = pd.read_pickle('/content/drive/MyDrive/Competition/y_train')\n",
        "y_val = pd.read_pickle('/content/drive/MyDrive/Competition/y_val')"
      ],
      "metadata": {
        "id": "Hp2zxmFOePcW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = pd.read_pickle('/content/drive/MyDrive/Competition/main_test')"
      ],
      "metadata": {
        "id": "5Pas7G7afBZa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X_train: {X_train.shape}')\n",
        "print(f'X_val: {X_val.shape}')\n",
        "print(f'Y_train: {y_train.shape}')\n",
        "print(f'Y_val: {y_val.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wa9HqWzDuW8",
        "outputId": "bea01341-bb6e-47dc-e24e-a8203d8014b4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (472432, 436)\n",
            "X_val: (118108, 436)\n",
            "Y_train: (472432,)\n",
            "Y_val: (118108,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del df_x\n",
        "del df_y"
      ],
      "metadata": {
        "id": "ywNN-ZvPEnaA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6cQ2hOAEuxF",
        "outputId": "b59dc301-c0a7-4da4-b392-dc568f2acea4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TF DATA**"
      ],
      "metadata": {
        "id": "f3C2focp_UrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a function prepare_tf_dataset to create TensorFlow datasets from input data (X, and optionally y for labels) for training, validation, or testing. The function performs the following steps:\n",
        "\n",
        "**One-Hot Encoding for Labels (y):**\n",
        "\n",
        "If y (labels) is provided, it converts the labels to one-hot encoded format using tf.one_hot with two classes.\n",
        "\n",
        "**Creating TensorFlow Dataset:**\n",
        "\n",
        "Uses tf.data.Dataset.from_tensor_slices to create a TensorFlow dataset.\n",
        "If y is provided, it creates a dataset with pairs (X, y) where X is the feature data and y is the one-hot encoded labels.\n",
        "If y is not provided, it creates a dataset only with X (feature data).\n",
        "\n",
        "**Shuffling (if specified):**\n",
        "\n",
        "If shuffle is set to True, shuffles the dataset using ds.shuffle.\n",
        "\n",
        "**Batching:**\n",
        "\n",
        "Batches the dataset into smaller chunks using ds.batch with a specified batch size (batch_size).\n",
        "drop_remainder is used to drop the last batch if its size is less than batch_size.\n",
        "\n",
        "**Prefetching:**\n",
        "\n",
        "Uses ds.prefetch to prefetch data for better performance during training. The argument autotune is set to tf.data.experimental.AUTOTUNE for automatic optimization.\n",
        "\n",
        "**Function Return:**\n",
        "\n",
        "Returns the prepared TensorFlow dataset.\n",
        "\n",
        "**Usage:**\n",
        "\n",
        "The function is then used to create TensorFlow datasets for training (train_ds), validation (val_ds), and testing (test_ds) using provided data (X_train, y_train, X_val, y_val, X_test)."
      ],
      "metadata": {
        "id": "fjXDK-Te9TBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_tf_dataset(\n",
        "    X,\n",
        "    batch_size,\n",
        "    y = None,\n",
        "    shuffle = False,\n",
        "    drop_remainder = False,\n",
        "):\n",
        "\n",
        "    \"\"\"\n",
        "    Creates a TensorFlow dataset for training, validation, or testing.\n",
        "\n",
        "    Parameters:\n",
        "    - X: Feature data.\n",
        "    - batch_size: Batch size for batching the dataset.\n",
        "    - y: Labels (optional).\n",
        "    - shuffle: Whether to shuffle the dataset (default: False).\n",
        "    - drop_remainder: Whether to drop the last batch if its size is less than batch_size (default: False).\n",
        "\n",
        "    Returns:\n",
        "    - TensorFlow dataset prepared for training, validation, or testing.\n",
        "    \"\"\"\n",
        "\n",
        "    size_of_dataset = len(X)\n",
        "    if y is not None:\n",
        "        y = tf.one_hot(y.astype(int), 2)\n",
        "        ds = tf.data.Dataset.from_tensor_slices((np.array(X.astype(np.float32)), y))\n",
        "    else:\n",
        "        ds = tf.data.Dataset.from_tensor_slices(np.array(X.astype(np.float32)))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=size_of_dataset)\n",
        "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n",
        "\n",
        "    autotune = tf.data.experimental.AUTOTUNE\n",
        "    ds = ds.prefetch(autotune)\n",
        "    return ds\n",
        "\n",
        "train_ds = prepare_tf_dataset(X_train, 16000, y_train)\n",
        "val_ds = prepare_tf_dataset(X_val, 16000, y_val)\n",
        "test_ds = prepare_tf_dataset(X_test, 16000)"
      ],
      "metadata": {
        "id": "jSPcIX-sChvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds)\n",
        "print(val_ds)"
      ],
      "metadata": {
        "id": "CIJITgMqD-y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining the TabNet Architecture**"
      ],
      "metadata": {
        "id": "NAzX1sMu-Smu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def glu(x, n_units=None):\n",
        "    \"\"\"Generalized linear unit nonlinear activation.\"\"\"\n",
        "    return x[:, :n_units] * tf.nn.sigmoid(x[:, n_units:])"
      ],
      "metadata": {
        "id": "RBRY0udkClKe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureBlock(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Implementation of a FL->BN->GLU block\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        feature_dim,\n",
        "        apply_glu = True,\n",
        "        bn_momentum = 0.9,\n",
        "        fc = None,\n",
        "        epsilon = 1e-5,\n",
        "    ):\n",
        "\n",
        "        \"\"\"\n",
        "        Initializes the FeatureBlock.\n",
        "\n",
        "        Parameters:\n",
        "        - feature_dim: Dimensionality of the features.\n",
        "        - apply_glu: Whether to apply GLU activation (default: True).\n",
        "        - bn_momentum: Batch normalization momentum.\n",
        "        - fc: Dense layer for shared weights.\n",
        "        - epsilon: Batch normalization epsilon.\n",
        "\n",
        "        Returns:\n",
        "        - None\n",
        "        \"\"\"\n",
        "        super(FeatureBlock, self).__init__()\n",
        "        self.apply_gpu = apply_glu\n",
        "        self.feature_dim = feature_dim\n",
        "        units = feature_dim * 2 if apply_glu else feature_dim # desired dimension gets multiplied by 2\n",
        "                                                              # because GLU activation halves it\n",
        "        self.fc = tf.keras.layers.Dense(units, use_bias=False) if fc is None else fc # shared layers can get re-used\n",
        "        self.bn = tf.keras.layers.BatchNormalization(momentum=bn_momentum, epsilon=epsilon)\n",
        "\n",
        "\n",
        "    def call(self, x, training = None):\n",
        "\n",
        "        \"\"\"\n",
        "        Defines the forward pass of FeatureBlock.\n",
        "\n",
        "        Parameters:\n",
        "        - x: Input features.\n",
        "        - training: Whether the model is in training mode.\n",
        "\n",
        "        Returns:\n",
        "        - Output of the FeatureBlock.\n",
        "        \"\"\"\n",
        "        x = self.fc(x) # inputs passes through the FC layer\n",
        "        x = self.bn(x, training=training) # FC layer output gets passed through the BN\n",
        "        if self.apply_gpu:\n",
        "            return glu(x, self.feature_dim) # GLU activation applied to BN output\n",
        "        return x\n",
        "\n",
        "\n",
        "class FeatureTransformer(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        feature_dim,\n",
        "        fcs = [],\n",
        "        n_total = 4,\n",
        "        n_shared = 2,\n",
        "        bn_momentum = 0.9,\n",
        "    ):\n",
        "\n",
        "        \"\"\"\n",
        "        Initializes the FeatureTransformer.\n",
        "\n",
        "        Parameters:\n",
        "        - feature_dim: Dimensionality of the features.\n",
        "        - fcs: List of shared Dense layers.\n",
        "        - n_total: Total number of FeatureBlocks.\n",
        "        - n_shared: Number of shared FeatureBlocks.\n",
        "        - bn_momentum: Batch normalization momentum.\n",
        "\n",
        "        Returns:\n",
        "        - None\n",
        "        \"\"\"\n",
        "        super(FeatureTransformer, self).__init__()\n",
        "        self.n_total, self.n_shared = n_total, n_shared\n",
        "\n",
        "        kwrgs = {\n",
        "            \"feature_dim\": feature_dim,\n",
        "            \"bn_momentum\": bn_momentum,\n",
        "        }\n",
        "\n",
        "        self.blocks = []\n",
        "        for n in range(n_total):\n",
        "            if fcs and n < len(fcs):\n",
        "                self.blocks.append(FeatureBlock(**kwrgs, fc=fcs[n])) # Building shared blocks by providing FC layers\n",
        "            else:\n",
        "                self.blocks.append(FeatureBlock(**kwrgs)) # Step dependent blocks without the shared FC layers\n",
        "\n",
        "    def call(self, x, training = None):\n",
        "\n",
        "        \"\"\"\n",
        "        Defines the forward pass of FeatureTransformer.\n",
        "\n",
        "        Parameters:\n",
        "        - x: Input features.\n",
        "        - training: Whether the model is in training mode.\n",
        "\n",
        "        Returns:\n",
        "        - Output of the FeatureTransformer.\n",
        "        \"\"\"\n",
        "        x = self.blocks[0](x, training=training)\n",
        "        for n in range(1, self.n_total):\n",
        "            # output from previous block gets multiplied by sqrt(0.5) and output of this block gets added\n",
        "            x = x * tf.sqrt(0.5) + self.blocks[n](x, training=training)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def shared_fcs(self):\n",
        "        return [self.blocks[i].fc for i in range(self.n_shared)]\n",
        "\n",
        "class AttentiveTransformer(tf.keras.Model):\n",
        "    def __init__(self, feature_dim):\n",
        "        super(AttentiveTransformer, self).__init__()\n",
        "        self.block = FeatureBlock(\n",
        "            feature_dim,\n",
        "            apply_glu=False,\n",
        "        )\n",
        "\n",
        "    def call(self, x, prior_scales, training=None):\n",
        "        x = self.block(x, training=training)\n",
        "        return sparsemax(x * prior_scales)\n",
        "\n",
        "class TabNet(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_features = 436,\n",
        "        feature_dim = 128,\n",
        "        output_dim = 128,\n",
        "        n_step = 2,\n",
        "        n_total = 4,\n",
        "        n_shared = 2,\n",
        "        relaxation_factor = 1.5,\n",
        "        bn_epsilon = 1e-5,\n",
        "        bn_momentum = 0.7,\n",
        "        sparsity_coefficient = 1e-5\n",
        "    ):\n",
        "\n",
        "        \"\"\"\n",
        "        Initializes the AttentiveTransformer.\n",
        "\n",
        "        Parameters:\n",
        "        - feature_dim: Dimensionality of the features.\n",
        "\n",
        "        Returns:\n",
        "        - None\n",
        "        \"\"\"\n",
        "        super(TabNet, self).__init__()\n",
        "        self.output_dim, self.num_features = output_dim, num_features\n",
        "        self.n_step, self.relaxation_factor = n_step, relaxation_factor\n",
        "        self.sparsity_coefficient = sparsity_coefficient\n",
        "\n",
        "        self.bn = tf.keras.layers.BatchNormalization(\n",
        "            momentum=bn_momentum, epsilon=bn_epsilon\n",
        "        )\n",
        "\n",
        "        kargs = {\n",
        "            \"feature_dim\": feature_dim + output_dim,\n",
        "            \"n_total\": n_total,\n",
        "            \"n_shared\": n_shared,\n",
        "            \"bn_momentum\": bn_momentum\n",
        "        }\n",
        "\n",
        "        # first feature transformer block is built first to get the shared blocks\n",
        "        self.feature_transforms = [FeatureTransformer(**kargs)]\n",
        "        self.attentive_transforms = []\n",
        "\n",
        "        # each step consists out of FT and AT\n",
        "        for i in range(n_step):\n",
        "            self.feature_transforms.append(\n",
        "                FeatureTransformer(**kargs, fcs=self.feature_transforms[0].shared_fcs)\n",
        "            )\n",
        "            self.attentive_transforms.append(\n",
        "                AttentiveTransformer(num_features)\n",
        "            )\n",
        "\n",
        "        # Final output layer\n",
        "        self.head = tf.keras.layers.Dense(2, activation=\"softmax\", use_bias=False)\n",
        "\n",
        "    def call(self, features, training = None):\n",
        "\n",
        "        \"\"\"\n",
        "        Defines the forward pass of AttentiveTransformer.\n",
        "\n",
        "        Parameters:\n",
        "        - x: Input features.\n",
        "        - prior_scales: Prior scales for attention.\n",
        "        - training: Whether the model is in training mode.\n",
        "\n",
        "        Returns:\n",
        "        - Output of the AttentiveTransformer.\n",
        "        \"\"\"\n",
        "\n",
        "        bs = tf.shape(features)[0] # get batch shape\n",
        "        out_agg = tf.zeros((bs, self.output_dim)) # empty array with outputs to fill\n",
        "        prior_scales = tf.ones((bs, self.num_features)) # prior scales initialised as 1s\n",
        "        importance = tf.zeros([bs, self.num_features]) # importances\n",
        "        masks = []\n",
        "\n",
        "        features = self.bn(features, training=training) # Batch Normalisation\n",
        "        masked_features = features\n",
        "\n",
        "        total_entropy = 0.0\n",
        "\n",
        "        for step_i in range(self.n_step + 1):\n",
        "            # (masked) features go through the FT\n",
        "            x = self.feature_transforms[step_i](\n",
        "                masked_features, training=training\n",
        "            )\n",
        "\n",
        "            # first FT is not used to generate output\n",
        "            if step_i > 0:\n",
        "                # first half of the FT output goes towards the decision\n",
        "                out = tf.keras.activations.relu(x[:, : self.output_dim])\n",
        "                out_agg += out\n",
        "                scale_agg = tf.reduce_sum(out, axis=1, keepdims=True) / (self.n_step - 1)\n",
        "                importance += mask_values * scale_agg\n",
        "\n",
        "\n",
        "            # no need to build the features mask for the last step\n",
        "            if step_i < self.n_step:\n",
        "                # second half of the FT output goes as input to the AT\n",
        "                x_for_mask = x[:, self.output_dim :]\n",
        "\n",
        "                # apply AT with prior scales\n",
        "                mask_values = self.attentive_transforms[step_i](\n",
        "                    x_for_mask, prior_scales, training=training\n",
        "                )\n",
        "\n",
        "                # recalculate the prior scales\n",
        "                prior_scales *= self.relaxation_factor - mask_values\n",
        "\n",
        "                # multiply the second half of the FT output by the attention mask to enforce sparsity\n",
        "                masked_features = tf.multiply(mask_values, features)\n",
        "\n",
        "                # entropy is used to penalize the amount of sparsity in feature selection\n",
        "                total_entropy += tf.reduce_mean(\n",
        "                    tf.reduce_sum(\n",
        "                        tf.multiply(-mask_values, tf.math.log(mask_values + 1e-15)),\n",
        "                        axis=1,\n",
        "                    )\n",
        "                )\n",
        "\n",
        "                # append mask values for later explainability\n",
        "                masks.append(tf.expand_dims(tf.expand_dims(mask_values, 0), 3))\n",
        "\n",
        "        #Per step selection masks\n",
        "        self.selection_masks = masks\n",
        "\n",
        "        # Final output\n",
        "        final_output = self.head(out)\n",
        "\n",
        "        # Add sparsity loss\n",
        "        loss = total_entropy / (self.n_step-1)\n",
        "        self.add_loss(self.sparsity_coefficient * loss)\n",
        "\n",
        "        return final_output, importance"
      ],
      "metadata": {
        "id": "dKiQcowYDdFu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabnet = TabNet(num_features = 436,\n",
        "                output_dim = 128,\n",
        "                feature_dim = 128,\n",
        "                n_step = 2,\n",
        "                relaxation_factor= 2,\n",
        "                sparsity_coefficient=2.5e-07,\n",
        "                n_shared = 2,\n",
        "                bn_momentum = 0.93)\n"
      ],
      "metadata": {
        "id": "dgkOm0Y7DiTk"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cbs = [tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=30, restore_best_weights=True\n",
        "    )]"
      ],
      "metadata": {
        "id": "2LUXRoOxEFeP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimiser\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=10)\n",
        "\n",
        "# Second loss in None because we also output the importances\n",
        "loss = [tf.keras.losses.CategoricalCrossentropy(from_logits=False), None]\n",
        "\n",
        "tabnet.compile(optimizer, loss=loss)"
      ],
      "metadata": {
        "id": "s_np7xWyER1J"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabnet.fit(train_ds,\n",
        "           epochs=100,\n",
        "           validation_data=val_ds,\n",
        "           callbacks=cbs,\n",
        "           verbose=1,\n",
        "          class_weight={\n",
        "              0:1,\n",
        "              1:20\n",
        "          })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOSWo_IxEWKu",
        "outputId": "8fce176f-a3f6-4e74-c296-8d8179ccdb9a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 35s 354ms/step - loss: 1.0754 - output_1_loss: 1.0754 - val_loss: 0.5089 - val_output_1_loss: 0.5089\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 11s 357ms/step - loss: 0.8860 - output_1_loss: 0.8860 - val_loss: 0.4425 - val_output_1_loss: 0.4425\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 9s 287ms/step - loss: 0.8099 - output_1_loss: 0.8099 - val_loss: 0.3795 - val_output_1_loss: 0.3795\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 9s 290ms/step - loss: 0.7740 - output_1_loss: 0.7740 - val_loss: 0.3422 - val_output_1_loss: 0.3422\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 8s 277ms/step - loss: 0.7432 - output_1_loss: 0.7432 - val_loss: 0.3331 - val_output_1_loss: 0.3331\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 9s 280ms/step - loss: 0.7148 - output_1_loss: 0.7148 - val_loss: 0.3315 - val_output_1_loss: 0.3315\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 8s 277ms/step - loss: 0.7004 - output_1_loss: 0.7004 - val_loss: 0.3323 - val_output_1_loss: 0.3323\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 8s 272ms/step - loss: 0.6881 - output_1_loss: 0.6881 - val_loss: 0.3267 - val_output_1_loss: 0.3267\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 9s 282ms/step - loss: 0.6659 - output_1_loss: 0.6659 - val_loss: 0.2981 - val_output_1_loss: 0.2981\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 8s 282ms/step - loss: 0.6436 - output_1_loss: 0.6436 - val_loss: 0.2996 - val_output_1_loss: 0.2996\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 8s 279ms/step - loss: 0.6296 - output_1_loss: 0.6296 - val_loss: 0.2950 - val_output_1_loss: 0.2950\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 9s 283ms/step - loss: 0.6241 - output_1_loss: 0.6241 - val_loss: 0.3086 - val_output_1_loss: 0.3086\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 8s 276ms/step - loss: 0.6108 - output_1_loss: 0.6108 - val_loss: 0.2959 - val_output_1_loss: 0.2959\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 8s 275ms/step - loss: 0.6013 - output_1_loss: 0.6013 - val_loss: 0.2811 - val_output_1_loss: 0.2811\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 9s 294ms/step - loss: 0.6007 - output_1_loss: 0.6007 - val_loss: 0.2857 - val_output_1_loss: 0.2857\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 9s 286ms/step - loss: 0.5726 - output_1_loss: 0.5726 - val_loss: 0.2624 - val_output_1_loss: 0.2624\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 9s 295ms/step - loss: 0.5537 - output_1_loss: 0.5537 - val_loss: 0.2599 - val_output_1_loss: 0.2599\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 9s 290ms/step - loss: 0.5398 - output_1_loss: 0.5398 - val_loss: 0.2356 - val_output_1_loss: 0.2356\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 8s 275ms/step - loss: 0.5354 - output_1_loss: 0.5354 - val_loss: 0.2762 - val_output_1_loss: 0.2762\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 8s 282ms/step - loss: 0.5436 - output_1_loss: 0.5436 - val_loss: 0.2699 - val_output_1_loss: 0.2699\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 8s 272ms/step - loss: 0.5275 - output_1_loss: 0.5275 - val_loss: 0.2461 - val_output_1_loss: 0.2461\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 9s 284ms/step - loss: 0.5125 - output_1_loss: 0.5125 - val_loss: 0.2614 - val_output_1_loss: 0.2614\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 8s 275ms/step - loss: 0.5024 - output_1_loss: 0.5024 - val_loss: 0.2505 - val_output_1_loss: 0.2505\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 9s 282ms/step - loss: 0.4879 - output_1_loss: 0.4879 - val_loss: 0.2471 - val_output_1_loss: 0.2471\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 8s 277ms/step - loss: 0.5074 - output_1_loss: 0.5074 - val_loss: 0.2513 - val_output_1_loss: 0.2513\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 8s 273ms/step - loss: 0.5179 - output_1_loss: 0.5179 - val_loss: 0.2372 - val_output_1_loss: 0.2372\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 8s 278ms/step - loss: 0.4857 - output_1_loss: 0.4857 - val_loss: 0.2564 - val_output_1_loss: 0.2564\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 9s 292ms/step - loss: 0.4713 - output_1_loss: 0.4713 - val_loss: 0.2314 - val_output_1_loss: 0.2314\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 8s 274ms/step - loss: 0.4562 - output_1_loss: 0.4562 - val_loss: 0.2380 - val_output_1_loss: 0.2380\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 9s 281ms/step - loss: 0.4483 - output_1_loss: 0.4483 - val_loss: 0.2153 - val_output_1_loss: 0.2153\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 9s 289ms/step - loss: 0.4498 - output_1_loss: 0.4498 - val_loss: 0.2628 - val_output_1_loss: 0.2628\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 8s 271ms/step - loss: 0.4410 - output_1_loss: 0.4410 - val_loss: 0.2250 - val_output_1_loss: 0.2250\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 9s 284ms/step - loss: 0.4340 - output_1_loss: 0.4340 - val_loss: 0.2215 - val_output_1_loss: 0.2215\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 9s 285ms/step - loss: 0.4326 - output_1_loss: 0.4326 - val_loss: 0.2201 - val_output_1_loss: 0.2201\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 8s 276ms/step - loss: 0.4236 - output_1_loss: 0.4236 - val_loss: 0.2182 - val_output_1_loss: 0.2182\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 9s 292ms/step - loss: 0.4183 - output_1_loss: 0.4183 - val_loss: 0.2207 - val_output_1_loss: 0.2207\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 8s 278ms/step - loss: 0.4146 - output_1_loss: 0.4146 - val_loss: 0.2363 - val_output_1_loss: 0.2363\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 9s 293ms/step - loss: 0.4039 - output_1_loss: 0.4039 - val_loss: 0.1962 - val_output_1_loss: 0.1962\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 9s 292ms/step - loss: 0.3938 - output_1_loss: 0.3938 - val_loss: 0.2058 - val_output_1_loss: 0.2058\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 9s 294ms/step - loss: 0.3872 - output_1_loss: 0.3872 - val_loss: 0.2194 - val_output_1_loss: 0.2194\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 9s 288ms/step - loss: 0.3972 - output_1_loss: 0.3972 - val_loss: 0.1963 - val_output_1_loss: 0.1963\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 8s 280ms/step - loss: 0.4112 - output_1_loss: 0.4112 - val_loss: 0.2193 - val_output_1_loss: 0.2193\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 9s 289ms/step - loss: 0.3939 - output_1_loss: 0.3939 - val_loss: 0.2151 - val_output_1_loss: 0.2151\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 8s 280ms/step - loss: 0.3727 - output_1_loss: 0.3727 - val_loss: 0.2237 - val_output_1_loss: 0.2237\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 9s 281ms/step - loss: 0.4010 - output_1_loss: 0.4010 - val_loss: 0.2501 - val_output_1_loss: 0.2501\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 9s 293ms/step - loss: 0.4203 - output_1_loss: 0.4203 - val_loss: 0.1947 - val_output_1_loss: 0.1947\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 8s 279ms/step - loss: 0.3853 - output_1_loss: 0.3853 - val_loss: 0.1901 - val_output_1_loss: 0.1901\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 9s 285ms/step - loss: 0.3651 - output_1_loss: 0.3651 - val_loss: 0.1787 - val_output_1_loss: 0.1787\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 9s 296ms/step - loss: 0.3540 - output_1_loss: 0.3540 - val_loss: 0.1882 - val_output_1_loss: 0.1882\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 8s 280ms/step - loss: 0.3474 - output_1_loss: 0.3474 - val_loss: 0.1942 - val_output_1_loss: 0.1942\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 9s 293ms/step - loss: 0.3574 - output_1_loss: 0.3574 - val_loss: 0.1871 - val_output_1_loss: 0.1871\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 9s 291ms/step - loss: 0.3553 - output_1_loss: 0.3553 - val_loss: 0.1996 - val_output_1_loss: 0.1996\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 9s 290ms/step - loss: 0.3497 - output_1_loss: 0.3497 - val_loss: 0.1989 - val_output_1_loss: 0.1989\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 9s 285ms/step - loss: 0.3427 - output_1_loss: 0.3427 - val_loss: 0.1840 - val_output_1_loss: 0.1840\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 9s 282ms/step - loss: 0.3243 - output_1_loss: 0.3243 - val_loss: 0.1914 - val_output_1_loss: 0.1914\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 9s 286ms/step - loss: 0.3265 - output_1_loss: 0.3265 - val_loss: 0.1969 - val_output_1_loss: 0.1969\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 8s 277ms/step - loss: 0.3345 - output_1_loss: 0.3345 - val_loss: 0.1849 - val_output_1_loss: 0.1849\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 9s 291ms/step - loss: 0.3237 - output_1_loss: 0.3237 - val_loss: 0.2039 - val_output_1_loss: 0.2039\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 8s 275ms/step - loss: 0.3247 - output_1_loss: 0.3247 - val_loss: 0.1901 - val_output_1_loss: 0.1901\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 9s 286ms/step - loss: 0.3159 - output_1_loss: 0.3159 - val_loss: 0.1919 - val_output_1_loss: 0.1919\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 9s 291ms/step - loss: 0.3063 - output_1_loss: 0.3063 - val_loss: 0.2364 - val_output_1_loss: 0.2364\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 8s 274ms/step - loss: 0.3109 - output_1_loss: 0.3109 - val_loss: 0.2125 - val_output_1_loss: 0.2125\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 9s 287ms/step - loss: 0.3191 - output_1_loss: 0.3191 - val_loss: 0.2123 - val_output_1_loss: 0.2123\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 9s 286ms/step - loss: 0.3125 - output_1_loss: 0.3125 - val_loss: 0.1789 - val_output_1_loss: 0.1789\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 8s 274ms/step - loss: 0.3014 - output_1_loss: 0.3014 - val_loss: 0.1969 - val_output_1_loss: 0.1969\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 9s 285ms/step - loss: 0.3058 - output_1_loss: 0.3058 - val_loss: 0.1858 - val_output_1_loss: 0.1858\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 8s 274ms/step - loss: 0.2991 - output_1_loss: 0.2991 - val_loss: 0.1817 - val_output_1_loss: 0.1817\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 8s 277ms/step - loss: 0.2890 - output_1_loss: 0.2890 - val_loss: 0.1786 - val_output_1_loss: 0.1786\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 8s 282ms/step - loss: 0.3022 - output_1_loss: 0.3022 - val_loss: 0.1867 - val_output_1_loss: 0.1867\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 8s 274ms/step - loss: 0.2862 - output_1_loss: 0.2862 - val_loss: 0.1733 - val_output_1_loss: 0.1733\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 8s 277ms/step - loss: 0.2775 - output_1_loss: 0.2775 - val_loss: 0.1688 - val_output_1_loss: 0.1688\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 8s 279ms/step - loss: 0.2848 - output_1_loss: 0.2848 - val_loss: 0.1743 - val_output_1_loss: 0.1743\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 8s 273ms/step - loss: 0.2817 - output_1_loss: 0.2817 - val_loss: 0.1643 - val_output_1_loss: 0.1643\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 9s 294ms/step - loss: 0.2718 - output_1_loss: 0.2718 - val_loss: 0.1650 - val_output_1_loss: 0.1650\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 8s 283ms/step - loss: 0.2813 - output_1_loss: 0.2813 - val_loss: 0.1576 - val_output_1_loss: 0.1576\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 8s 272ms/step - loss: 0.2786 - output_1_loss: 0.2786 - val_loss: 0.1533 - val_output_1_loss: 0.1533\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 8s 277ms/step - loss: 0.2776 - output_1_loss: 0.2776 - val_loss: 0.1722 - val_output_1_loss: 0.1722\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 9s 285ms/step - loss: 0.2732 - output_1_loss: 0.2732 - val_loss: 0.1487 - val_output_1_loss: 0.1487\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 8s 274ms/step - loss: 0.2652 - output_1_loss: 0.2652 - val_loss: 0.1611 - val_output_1_loss: 0.1611\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 9s 283ms/step - loss: 0.2519 - output_1_loss: 0.2519 - val_loss: 0.1695 - val_output_1_loss: 0.1694\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 9s 287ms/step - loss: 0.2582 - output_1_loss: 0.2582 - val_loss: 0.1726 - val_output_1_loss: 0.1726\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 8s 279ms/step - loss: 0.2625 - output_1_loss: 0.2625 - val_loss: 0.1584 - val_output_1_loss: 0.1584\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 9s 290ms/step - loss: 0.2502 - output_1_loss: 0.2502 - val_loss: 0.1813 - val_output_1_loss: 0.1813\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 8s 274ms/step - loss: 0.2486 - output_1_loss: 0.2486 - val_loss: 0.1723 - val_output_1_loss: 0.1723\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 9s 285ms/step - loss: 0.2416 - output_1_loss: 0.2416 - val_loss: 0.1644 - val_output_1_loss: 0.1644\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 8s 272ms/step - loss: 0.2518 - output_1_loss: 0.2518 - val_loss: 0.1834 - val_output_1_loss: 0.1834\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 9s 286ms/step - loss: 0.2654 - output_1_loss: 0.2654 - val_loss: 0.1788 - val_output_1_loss: 0.1787\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 8s 275ms/step - loss: 0.2583 - output_1_loss: 0.2583 - val_loss: 0.1821 - val_output_1_loss: 0.1821\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 9s 292ms/step - loss: 0.2458 - output_1_loss: 0.2458 - val_loss: 0.1559 - val_output_1_loss: 0.1559\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 9s 293ms/step - loss: 0.2447 - output_1_loss: 0.2447 - val_loss: 0.1625 - val_output_1_loss: 0.1625\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 8s 278ms/step - loss: 0.2394 - output_1_loss: 0.2394 - val_loss: 0.1660 - val_output_1_loss: 0.1660\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 9s 294ms/step - loss: 0.2353 - output_1_loss: 0.2353 - val_loss: 0.1659 - val_output_1_loss: 0.1659\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 9s 290ms/step - loss: 0.2378 - output_1_loss: 0.2378 - val_loss: 0.1568 - val_output_1_loss: 0.1568\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 9s 284ms/step - loss: 0.2477 - output_1_loss: 0.2477 - val_loss: 0.1518 - val_output_1_loss: 0.1518\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 9s 290ms/step - loss: 0.2471 - output_1_loss: 0.2471 - val_loss: 0.1654 - val_output_1_loss: 0.1654\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 8s 277ms/step - loss: 0.2444 - output_1_loss: 0.2444 - val_loss: 0.1600 - val_output_1_loss: 0.1600\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 9s 291ms/step - loss: 0.2679 - output_1_loss: 0.2679 - val_loss: 0.1814 - val_output_1_loss: 0.1814\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 8s 281ms/step - loss: 0.2478 - output_1_loss: 0.2478 - val_loss: 0.1752 - val_output_1_loss: 0.1752\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 9s 288ms/step - loss: 0.2373 - output_1_loss: 0.2373 - val_loss: 0.1724 - val_output_1_loss: 0.1724\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 9s 286ms/step - loss: 0.2400 - output_1_loss: 0.2400 - val_loss: 0.1688 - val_output_1_loss: 0.1688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x788a46b639a0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tabnet.save_weights(\"/content/drive/MyDrive/Competition/Models_check/tabnet_weights.h5\")\n"
      ],
      "metadata": {
        "id": "4VYzGarIc3VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "val_preds, val_imps = tabnet.predict(val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcz64dPLmSZL",
        "outputId": "e2bc6a87-4448-4755-8daa-920f9893608d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 2s 99ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test ROC AUC', np.round(roc_auc_score(y_val, val_preds[:, 1]), 4))\n",
        "print('Test PR AUC', np.round(average_precision_score(y_val, val_preds[:, 1]), 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL4HLofCmbQo",
        "outputId": "04ec2ede-a3fb-461b-ea5f-dac1498c98b7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test ROC AUC 0.9168\n",
            "Test PR AUC 0.6232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "____________________"
      ],
      "metadata": {
        "id": "vG732FaEDdBc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_________________________"
      ],
      "metadata": {
        "id": "WPyYuLMvDd3E"
      }
    }
  ]
}